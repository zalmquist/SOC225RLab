---
title: "lab12: open policing"
subtitle: "Soc 225: Data & Society"
author: "[PUT YOUR NAME HERE]"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
---

```{r,message=FALSE,warning=FALSE}
## Run this code, to manage packages and install as needed.
# Install pacman
if (!require("pacman")) install.packages("pacman", repos = "http://cran.us.r-project.org")
# p_load function loads packages if installed, or install then loads otherwise
pacman::p_load(tidyverse,lubridate)
```

# Agenda
- Introduction and setup
- Basic explorations of data
- Benchmark test
  - Stop rates
  - Search rates
  - Caveats about the benchmark test
- Outcome test
  - Adjusting for location
  - Challenge

# 1. Introduction and setup
In this lab, we will learn how to analyze traffic stop data and apply key statistical tests to measure racial disparities and possible bias using skills we have learned in previous labs. The data we use is from [The Stanford Open Policing Project](https://openpolicing.stanford.edu/data/). We will look at data from Philadelphia today. While working on the lab, think about possible caveats of our statistical tests and factors that could bring bias to our findings. 

First, let's load relevant libraries, and read the data set. 

**Question 1.1. Load packages `tidyverse` and `lubridate`.** 
```{r}
library(tidyverse)
library(lubridate)
```

**Question 1.2. Load the data set "pa_philadelphia_2020_04_01.csv". Assign the data frame with name "stops".**
```{r}
unzip("data/pa_philadelphia_2020_04_01.csv.zip",exdir="data")
stops = read_csv("data/pa_philadelphia_2020_04_01.csv")
```

**Question 1.3. Check what columns and how many rows our `stop` data frame contains.**
```{r}

```

We'll also prepare for some additional data and fixed values that we'll be using.
```{r}
# baseline population 2017
population_2017 <- tibble(
  subject_race = c(
    "asian/pacific islander", "black", "hispanic", "other/unknown","white"
  ),
  num_people = c(110864, 648846, 221777, 39858, 548312)
) %>% 
  mutate(subject_race = as.factor(subject_race))

# geolocation
center_lat <- 39.9525839
center_lng <- -75.1652215
```

# 2. Basic explorations of data

Let's first check what range does our data cover. 

**Question 2.1. Check the min() and max() dates in our dataframe.**
```{r}
# min(stops$date)
# max(stops$date)
```

Since we only have four and a half months of data for 2018, let’s filter it out. Note that there are ways to deal with partial years in analysis, but to make things easier for ourselves, let’s focus on 2014-2017. We can with get the year from the date using year() from the `lubridate` package.
```{r}
stops <- stops%>% 
  filter(year(date)<2018)
```

**Question 2.2. Next, take a look at the `type` column and only keep the types to "vehicular", i.e. traffic stops. How many rows do you have now?**
```{r}
stops <- stops %>% 
  filter(type == "vehicular")
```

Next, let's find stop counts over race. 
```{r}
stops %>% 
  count(subject_race)
```
**Question 2.3. Make another table that returns the proportion of stops by race. (There are a few equivalent ways to do this - choose the method that feels most natural to you!) What first impression do you get?**
```{r}
stops %>% 
  count(subject_race) %>% 
  mutate(prop = n/sum(n))
```
The next step would be counting how many stops by year and race. Thinking we would have 6 \times 4 = 24 rows, it might be helpful to look at a simple visualization:
```{r}
stops %>% 
  count(year = year(date), subject_race) %>% # count by each year and race
  ggplot(aes(x = year, y = n, color = subject_race)) +
  geom_point() +
  geom_line() 
```
From this plot we see that, at least for black and white drivers, the annual trends are very different by race. (It’s hard to tell from this plot for drivers of other races because the counts are comparatively so much smaller.) All races experienced a spike in enforcement in 2015, but thereafter, there were fewer white drivers stopped (in 2016 and 2017), whereas there continued to be an increase in number of black drivers stopped over those two years.

**Question 2.4. Based on the exploration we just did, can you draw the conclusion that traffic stops are racially biased against blacks? What factors may make this conclusion invalid?**

It seems like the disparities could be changing over time. Here, we’ll filter to only 2017 and focus on that data for the rest of our analysis (and overwrite stops).
```{r}
stops <- stops %>% filter(year(date) == 2017)
```

# 3. Benchmark test
We just saw that over two-thirds of stops were of black drivers. The by-race stop counts are only meaningful, though, when compared to some baseline. If the Philadelphia population was about two-thirds black, then two-thirds of stops being of black drivers wouldn’t be at all surprising.

## Stop rates
In order to do this baseline comparison, we need to understand the racial demographics in our Philly population data. The data as we’ve given it to you in the beginning has raw population numbers. To make it useful, we’ll need to compute the proportion of Philadelphia residents in each demographic group.

**Question 3.1. Use data frame `population_2017`, compute the proportion of each race groups with regard to the total population.**
(Check the hints if you have troubles)
```{r}

```

As an eyeball comparison leads us to see that black drivers are being stopped disproportionately, relative to the city’s population. But let’s be a bit more rigorous about this. If we join the two tables together, we can compute stop rates by race (i.e., number of stops per person). Remember to take into account how many years are in your stop data, in order to get a true value of stops per capita; we’re using only 2017 for stops and for population, so we’re in good shape. Before making the join, we'll combine categories of "other" and "unknown" into one, corresponding with what we have in the population data.
```{r}
stops <- stops %>% 
  mutate(subject_race = case_when(subject_race %in% c("other","unknown") ~ "other/unknown",
                                  TRUE~subject_race)) 
```


**Question 3.2. Merge `stops` and `population_2017` using `left_join`. Then generate a new variable, "stop_rate" that equals the number of stops divided by population count for each race group.**
(Check the hints if you have troubles)

```{r}

```
**Question 3.3. Now we can divide the black stop rate by the white stop rate to be able to make a quantitative statement about how much more often black drivers are stops compared to white drivers, relative to their share of the city’s population. What do you get?**

## Search rates
Let’s do the same sort of benchmark comparison for search and frisk rates. These are easier than the last one since we don’t need an external population benchmark. We can use the stopped population as our baseline, defining search rate to be proportion of stopped people who were subsequently searched, and frisk rate as proportion of stopped people who were subsequently frisked. Let’s get these values by race. Note that with functions like mean(), if any of the values that are being averaged are `NA`, the output value of the mean will simply be `NA`. We pass the argument `na.rm = T` into `mean()` to avoid this issue. 

```{r}
stops %>% 
  group_by(subject_race) %>% 
  summarize(
    search_rate = mean(search_conducted, na.rm = T),
    frisk_rate = mean(frisk_performed, na.rm = T)
  )
```
Now let’s dive into these results! As with the stop rates, we can make a quantitative claim about disparities in search and frisk rates by dividing the minority rate by the white rate. Here we see that among drivers who were stopped, black drivers were searched at a rate 1.5 times higher than white drivers, and Hispanic drivers were searched at a rate 1.2 times higher than white drivers. Black drivers were frisked at a rate 2.1 times higher than white drivers were, and Hispanic drivers were frisked at a rate 1.5 times higher than white drivers were.

## Caveats about the benchmark test

**Question 3.4. While these baseline stats give us a sense that there are racial disparities in policing practices in Philadelphia, they are not evidence of discrimination. What arguments/critique can you think of about our findings?**
(Check the hints for discussion)

# 4. Outcome test
To circumvent the benchmarking problem, it’s common to turn to the search decision, rather than the stop decision. This is because we have a notion of what a “successful” search is. The legal justification for performing a search is probable cause that the driver possesses contraband. So a successful search is one which uncovers contraband.

We thus turn to rates of successful searches. That is, what proportion of searches, by race, were successful? This proportion is known as the contraband recovery rate, or the “hit rate.” If racial groups have different hit rates, it can imply that racial groups are being subjected to different standards.

As a caricatured example, suppose among white drivers who were searched, officers found contraband 99% of the time, while among black drivers who were searched, officers found contraband only 1% of the time. This would lead us to believe that officers made sure they were certain white individuals had contraband before deciding to search, but that they were searching black individuals on a whiff of evidence.

Let’s investigate hit rates by race in Philly in 2017.

**Question 4.1. Among the searched conducted, find the mean of "contraband_found" by race groups. What do you find about the hit rates of different groups?**
```{r}
stops %>% 
  filter(search_conducted) %>% 
  group_by(subject_race) %>% 
  summarize(
    hit_rate = mean(contraband_found, na.rm = T)
  )
```
We see that hit rates are slightly lower for black and Hispanic drivers than for white drivers.

However, what if hit rates vary by police district? If the bar for stopping people, irrespective of race, is lower in certain police districts, and black individuals are more likely to live in neighborhoods in those districts, then the observed disparities may not reflect bias.

## Adjusting for location

**Question 4.2. Now let's compute hit rates by race *and* district. Name your result `hit_rates`.**
```{r}
hit_rates <- 
  stops %>% 
  filter(search_conducted) %>% 
  group_by(subject_race, district) %>% 
  summarize(hit_rate = mean(contraband_found, na.rm = T))

hit_rates
```

Again, this is too many hit rates to compare in one table. To plot the hit rates of black vs. white drivers and of Hispanic vs. white drivers, we need to reshape our table to have each row containing a district, a minority race, minority hit rate in that district, and white hit rate in that district. We’ll walk you through the code below that reshapes the data for us. Some new verbs to learn:

`pivot_longer()` takes as many columns as you'd like and makes two new columns:

- a *names_to* column, with the column names as categories
- a *values to* column, with all of the original column values

`pivot_wider()` inverts `pivot_longer()` by taking two columns and pivoting them up into multiple columns.

```{r}
# Reshape table to show hit rates of minorities vs white drivers
  hit_rates <- hit_rates %>% 
  filter(subject_race %in% c("black", "white", "hispanic")) %>% 
  pivot_wider(names_from = subject_race, values_from = hit_rate) %>%
  rename(white_hit_rate = white) %>% 
  pivot_longer(c(black, hispanic), names_to = "minority_race", values_to = "minority_hit_rate") %>%
  arrange(district)

```

Now let's plot it!

**Question 4.3. Complete the below code to plot the `hit_rates` data frame with `white_hit_rate` on the x axis and `minority_hit_rate` on the y axis.**

```{r}
# We'll use this just to make our axes' limits nice and even
max_hit_rate <-
  hit_rates %>% 
  select(ends_with("hit_rate")) %>% 
  max()

hit_rates %>% 
  ggplot(
                            # fill in the blank: set the x axis
                            # fill in the blank: set the y axis
  )) +                      # fill in the blank: choose appropriate plot type
  +      
  # This sets a diagonal reference line (line of equal hit rates)
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  # These next few lines just make the axes pretty and even
  scale_x_continuous("White hit rate", 
    limits = c(0, max_hit_rate + 0.01),
    labels = scales::percent
  ) +
  scale_y_continuous("Minority hit rate", 
    limits = c(0, max_hit_rate + 0.01),
    labels = scales::percent
  ) +
  # This makes sure that 1% on the x-axis is the same as 1% on the y-axis
  coord_fixed() 
+              # fill in the blank: compare black v. white and                      Hispanic v. white side by side, in panels
  
```

What do you find from the plots?

## Challenge

The above analysis is a good start. However, it’s hard to tell where the mass is. That is, maybe the points above the dotted line (i.e., the points where minority hit rates are higher than white hit rates), maybe those districts have all of Philadelphia’s population, and the districts below the line only represent a few people. While this is unlikely, it’s still good to have a marker of how much weight or emphasis to give each of the points on our plot.

It is therefore meaningful to size each of the points by number of searches. Give it a try! 
(Check hints if you'd like to dig further into the question)
```{r}
# Step 1
# Get corresponding number of searches (to size points).
# Again, for each district we want to know the number of white+black searches
# and white+Hispanic searches. This requires the same spreading and gathering
# as our previous data-munging.
```

```{r}
# Step 2
# Merge `hit_rates` with the data frame you generated in Step 1.
```

```{r}
# Step 3
# Plot the new data frame!
```

Hints
3.1. Your code should look like this:
```{r}
population_2017 %>% 
  mutate(prop = num_people / sum(num_people))
```

3.2. Your code should look like this:
```{r}
stops %>% 
  count(subject_race) %>% 
  left_join(
    population_2017,
    by = "subject_race"
  ) %>% 
  mutate(stop_rate = n / num_people)
```

3.4. 
For the stop rate benchmark, what we really want to know is what the true distribution is for individuals breaking traffic laws or exhibiting other criminal behavior in their vehicles. If black and Hispanic drivers are disproportionately stopped relative to their rates of offending, that would be stronger evidence. Some people then proposed to use benchmarks that approximate those offending rates, like arrests, for example. However, we know arrests to themselves be racially skewed (especially for low-level drug offenses, for example), so it wouldn’t give us the true offending population’s racial distribution. Furthermore, only 2.1% of stops result in an arrest, so the arrested population will naturally not match the stopped population.

An even simpler critique of the population benchmark for stop rates is that it doesn’t account for possible race-specific differences in driving behavior, including amount of time spent on the road (and adherence to traffic laws, as mentioned above). If black drivers, hypothetically, spend more time on the road than white drivers, that in and of itself could explain the higher stop rates we see for black drivers, even in the absence of discrimination.

Search and frisk rates are slightly less suspect, since among the stopped population, it’s more reasonable to believe that people of different races offend at equal rates. In the context of searches, this means assuming that all races exhibit probable cause of possessing contraband at equal rates. And in the case of frisks, this means assuming that all races exhibit reasonable articulable suspicion of possessing a weapon at equal rates. Of course, one could also argue against these assumptions. One could claim that the stopped population isn’t a good measure of the true racial distribution of probable cause. This is all to say that while benchmark stats are a good place to start, more investigation is required before we can draw any conclusions.

Challenge: Your code should look like this:

```{r}
search_counts <-
  stops %>% 
  filter(
    search_conducted, 
    subject_race %in% c("black", "white", "hispanic")
  ) %>%  
  count(district, subject_race) %>% 
  pivot_wider(names_from = subject_race, values_from = n) %>% 
  rename(num_white_searches = white) %>% 
  pivot_longer(c(black, hispanic), names_to = "minority_race", values_to = "num_minority_searches") %>% 
  mutate(num_searches = num_minority_searches + num_white_searches) %>% 
  select(district, minority_race, num_searches)

hit_rates %>% 
  left_join(
    search_counts, 
    by = c("district", "minority_race")
  ) %>% 
  ggplot(aes(
    x = white_hit_rate,
    y = minority_hit_rate
  )) +
  geom_point(aes(size = num_searches), pch = 21) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  scale_x_continuous("White hit rate", 
    limits = c(0, max_hit_rate + 0.01),
    labels = scales::percent
  ) +
  scale_y_continuous("Minority hit rate", 
    limits = c(0, max_hit_rate + 0.01),
    labels = scales::percent
  ) +
  coord_fixed() +
  facet_grid(. ~ minority_race)
```



# References

[Stanford Open Policing Tutorials](https://openpolicing.stanford.edu/tutorials/#)